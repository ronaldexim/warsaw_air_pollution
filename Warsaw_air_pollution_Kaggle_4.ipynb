{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wwo-hist\n",
      "  Downloading wwo_hist-0.0.4.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: wwo-hist\n",
      "  Building wheel for wwo-hist (setup.py): started\n",
      "  Building wheel for wwo-hist (setup.py): finished with status 'done'\n",
      "  Created wheel for wwo-hist: filename=wwo_hist-0.0.4-py3-none-any.whl size=4218 sha256=515dbb8c6fb887f31d6419bbcdabf80f12d36dd7c177d77efe7a4ea63e65117f\n",
      "  Stored in directory: c:\\users\\remek\\appdata\\local\\pip\\cache\\wheels\\47\\67\\a6\\977ac091198b98e5133420721fc4d04575c8db9564e02c8759\n",
      "Successfully built wwo-hist\n",
      "Installing collected packages: wwo-hist\n",
      "Successfully installed wwo-hist-0.0.4\n"
     ]
    }
   ],
   "source": [
    "# !pip install wwo-hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Retrieving weather data for warsaw\n",
      "\n",
      "\n",
      "Currently retrieving data for warsaw: from 2014-12-25 to 2014-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.851697\n",
      "Currently retrieving data for warsaw: from 2015-01-01 to 2015-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.514303\n",
      "Currently retrieving data for warsaw: from 2015-02-01 to 2015-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.819765\n",
      "Currently retrieving data for warsaw: from 2015-03-01 to 2015-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.935783\n",
      "Currently retrieving data for warsaw: from 2015-04-01 to 2015-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.627262\n",
      "Currently retrieving data for warsaw: from 2015-05-01 to 2015-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.890920\n",
      "Currently retrieving data for warsaw: from 2015-06-01 to 2015-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:09.214381\n",
      "Currently retrieving data for warsaw: from 2015-07-01 to 2015-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:10.539838\n",
      "Currently retrieving data for warsaw: from 2015-08-01 to 2015-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:12.208348\n",
      "Currently retrieving data for warsaw: from 2015-09-01 to 2015-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:13.452023\n",
      "Currently retrieving data for warsaw: from 2015-10-01 to 2015-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:14.606988\n",
      "Currently retrieving data for warsaw: from 2015-11-01 to 2015-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:15.847622\n",
      "Currently retrieving data for warsaw: from 2015-12-01 to 2015-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:17.308754\n",
      "Currently retrieving data for warsaw: from 2016-01-01 to 2016-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:18.999232\n",
      "Currently retrieving data for warsaw: from 2016-02-01 to 2016-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:20.255841\n",
      "Currently retrieving data for warsaw: from 2016-03-01 to 2016-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:21.472623\n",
      "Currently retrieving data for warsaw: from 2016-04-01 to 2016-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:22.838969\n",
      "Currently retrieving data for warsaw: from 2016-05-01 to 2016-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:24.189330\n",
      "Currently retrieving data for warsaw: from 2016-06-01 to 2016-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:25.463924\n",
      "Currently retrieving data for warsaw: from 2016-07-01 to 2016-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:26.671735\n",
      "Currently retrieving data for warsaw: from 2016-08-01 to 2016-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:28.343227\n",
      "Currently retrieving data for warsaw: from 2016-09-01 to 2016-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:29.429326\n",
      "Currently retrieving data for warsaw: from 2016-10-01 to 2016-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:30.727854\n",
      "Currently retrieving data for warsaw: from 2016-11-01 to 2016-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:32.056304\n",
      "Currently retrieving data for warsaw: from 2016-12-01 to 2016-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:33.470527\n",
      "Currently retrieving data for warsaw: from 2017-01-01 to 2017-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:35.169018\n",
      "Currently retrieving data for warsaw: from 2017-02-01 to 2017-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:36.337864\n",
      "Currently retrieving data for warsaw: from 2017-03-01 to 2017-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:37.602532\n",
      "Currently retrieving data for warsaw: from 2017-04-01 to 2017-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:38.846205\n",
      "Currently retrieving data for warsaw: from 2017-05-01 to 2017-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:40.214534\n",
      "Currently retrieving data for warsaw: from 2017-06-01 to 2017-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:41.532015\n",
      "Currently retrieving data for warsaw: from 2017-07-01 to 2017-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:43.011059\n",
      "Currently retrieving data for warsaw: from 2017-08-01 to 2017-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:44.280668\n",
      "Currently retrieving data for warsaw: from 2017-09-01 to 2017-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:45.457492\n",
      "Currently retrieving data for warsaw: from 2017-10-01 to 2017-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:46.761055\n",
      "Currently retrieving data for warsaw: from 2017-11-01 to 2017-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:48.117429\n",
      "Currently retrieving data for warsaw: from 2017-12-01 to 2017-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:49.405964\n",
      "Currently retrieving data for warsaw: from 2018-01-01 to 2018-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:50.814175\n",
      "Currently retrieving data for warsaw: from 2018-02-01 to 2018-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:51.892326\n",
      "Currently retrieving data for warsaw: from 2018-03-01 to 2018-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:53.142985\n",
      "Currently retrieving data for warsaw: from 2018-04-01 to 2018-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:54.434525\n",
      "Currently retrieving data for warsaw: from 2018-05-01 to 2018-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:55.631337\n",
      "Currently retrieving data for warsaw: from 2018-06-01 to 2018-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:56.839099\n",
      "Currently retrieving data for warsaw: from 2018-07-01 to 2018-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:58.132643\n",
      "Currently retrieving data for warsaw: from 2018-08-01 to 2018-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:59.341411\n",
      "Currently retrieving data for warsaw: from 2018-09-01 to 2018-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:00.667841\n",
      "Currently retrieving data for warsaw: from 2018-10-01 to 2018-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:02.016295\n",
      "Currently retrieving data for warsaw: from 2018-11-01 to 2018-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:03.239967\n",
      "Currently retrieving data for warsaw: from 2018-12-01 to 2018-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:04.508608\n",
      "Currently retrieving data for warsaw: from 2019-01-01 to 2019-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:05.832074\n",
      "Currently retrieving data for warsaw: from 2019-02-01 to 2019-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:07.015876\n",
      "Currently retrieving data for warsaw: from 2019-03-01 to 2019-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:08.308456\n",
      "Currently retrieving data for warsaw: from 2019-04-01 to 2019-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:09.533174\n",
      "Currently retrieving data for warsaw: from 2019-05-01 to 2019-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:10.896536\n",
      "Currently retrieving data for warsaw: from 2019-06-01 to 2019-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:12.265847\n",
      "Currently retrieving data for warsaw: from 2019-07-01 to 2019-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:13.744894\n",
      "Currently retrieving data for warsaw: from 2019-08-01 to 2019-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:15.145151\n",
      "Currently retrieving data for warsaw: from 2019-09-01 to 2019-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:16.453680\n",
      "Currently retrieving data for warsaw: from 2019-10-01 to 2019-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:17.755177\n",
      "Currently retrieving data for warsaw: from 2019-11-01 to 2019-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:18.957994\n",
      "Currently retrieving data for warsaw: from 2019-12-01 to 2019-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:20.330294\n",
      "Currently retrieving data for warsaw: from 2020-01-01 to 2020-01-10\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:21.176059\n",
      "\n",
      "\n",
      "export warsaw completed!\n",
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# uzyskanie 'prognozy' danych pogodowych wg https://github.com/MichalPorwisz/warsaw-pollution\n",
    "\n",
    "import os\n",
    "\n",
    "from wwo_hist import retrieve_hist_data\n",
    "\n",
    "frequency = 1\n",
    "start_date = '25-DEC-2014'\n",
    "end_date = '10-JAN-2020'\n",
    "# TODO: Put your key\n",
    "api_key = '' \n",
    "location_list = ['warsaw']\n",
    "# TODO: inside they filter out some columns - maybe try seeing all\n",
    "hist_weather_data = retrieve_hist_data(api_key,\n",
    "                                location_list,\n",
    "                                start_date,\n",
    "                                end_date,\n",
    "                                frequency,\n",
    "                                location_label = False,\n",
    "                                export_csv = True,\n",
    "                                store_df = True)\n",
    "print('done')\n",
    "\n",
    "# path like this because chdir changed directory\n",
    "hist_weather_data[0].to_csv('warsaw_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "from os import path\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer, accuracy_score\n",
    "from ml_metrics import rmse\n",
    "\n",
    "from functools import partial\n",
    "from hyperopt import hp\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beginFE():\n",
    "    \n",
    "    for one in globals().copy().keys():\n",
    "        if one.endswith('_feats'):\n",
    "            del globals()[one]\n",
    "    if 'feats' in globals():\n",
    "        del globals()['feats']\n",
    "    \n",
    "    train = pd.read_hdf('train_warsaw.h5')\n",
    "    train = train.rename(columns={'timestamp': 'date'}).reset_index()\n",
    "    train.drop( columns=['timestamp'], inplace = True)\n",
    "    test = pd.read_hdf('test_warsaw.h5')\n",
    "    test = test.rename(columns={'timestamp': 'date'}).reset_index()\n",
    "    test.drop( columns=['timestamp'], inplace = True)\n",
    "    \n",
    "    df = pd.concat([train, test], sort=True)\n",
    "    df.sort_values(['date', 'id'], inplace=True)\n",
    "    \n",
    "    # fragment kodu dodający prognozę pogody - proste użycie tych cech i ich agregatów pogorszyło wynik\n",
    "    \n",
    "#     weather_forrecast = pd.read_csv('warsaw_full.csv')\n",
    "#     weather_forrecast['date_time'] = pd.to_datetime(weather_forrecast['date_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "#     df = pd.merge(df, weather_forrecast, left_on='date', right_on='date_time')\n",
    "#     df.drop( columns=['Unnamed: 0', 'date_time', 'moonrise', 'moonset', 'sunrise', 'sunset'], inplace = True)\n",
    "    \n",
    "#     forrecast_feats = ['maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour', 'uvIndex_y', 'uvIndex.1', 'moon_illumination', \n",
    "#                        'DewPointC', 'FeelsLikeC', 'HeatIndexC', 'WindChillC', 'WindGustKmph', 'cloudcover', 'humidity_y', \n",
    "#                        'precipMM', 'pressure_y', 'tempC', 'visibility_y', 'winddirDegree', 'windspeedKmph']\n",
    "\n",
    "    forrecast_feats = []\n",
    "        \n",
    "    df['hour']    = df.date.dt.hour\n",
    "    df['day_m']   = df.date.dt.day\n",
    "    df['month']   = df.date.dt.month\n",
    "    df['year']    = df.date.dt.year\n",
    "    df['week_y']  = df.date.dt.week\n",
    "    df['day_y']   = df.date.dt.dayofyear\n",
    "    df['day_w']   = df.date.dt.dayofweek\n",
    "    df['quarter'] = df.date.dt.quarter\n",
    "    df['hour_w']  = df.date.dt.hour + df.date.dt.dayofweek * 24\n",
    "    \n",
    "    df['pm25_log']      = (np.log(df[ df['pm25']>0 ]['pm25']+1))\n",
    "    \n",
    "    time_feats = ['quarter', 'month', 'week_y', 'day_y', 'day_m', 'day_w', 'hour', 'hour_w', 'year']\n",
    "\n",
    "    black_list_feats = ['id', 'pm25', 'pm25_log', 'is_non_cont', 'id_dif', 'd_time', 'cont_nr']\n",
    "\n",
    "    return df, time_feats, black_list_feats, forrecast_feats\n",
    "    \n",
    "def endFE(df, black_list_feats):\n",
    "\n",
    "    # listy kawałków\n",
    "    def count_cont_nr(flag):\n",
    "        global value\n",
    "        if flag:\n",
    "            value = 1\n",
    "        else:\n",
    "            value += 1\n",
    "        return int(value)\n",
    "    \n",
    "    df['is_non_cont'] = df.shift(1).id != (df.id - 1)\n",
    "    df['id_dif'] = (df.id - df.shift(1).id).fillna(0).astype(int)\n",
    "    df['d_time'] = df.date - df.shift(1).date\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['cont_nr'] = df.apply(lambda x: count_cont_nr(x['is_non_cont']), axis=1)\n",
    "    begin_idx = df.loc[df['is_non_cont']].index.values.astype(int)\n",
    "    end_idx = (df.shift(1).loc[df['is_non_cont']]['cont_nr'].shift(-1) + \n",
    "               df.loc[df['is_non_cont']].index.values).values.astype(int)\n",
    "    end_idx[-1] = int(len(df))\n",
    "    parts = []\n",
    "    for i in range(len(begin_idx)):\n",
    "        parts.append( df.iloc[ begin_idx[i] : (end_idx[i]) ].copy() )\n",
    "        \n",
    "    train, test = df[ ~df.pm25.isnull() ], df[ df.pm25.isnull() ]\n",
    "    \n",
    "    num_feats = df.select_dtypes(include=[np.number, bool]).columns.values\n",
    "    num_feats = [feat for feat in num_feats if feat not in black_list_feats]\n",
    "    omit_feats = [x for x in df.columns if x not in num_feats]\n",
    "            \n",
    "#     df.fillna(-1, inplace=True)\n",
    "#     df = df.iloc[24:,]\n",
    "    \n",
    "    return df, train, test, parts, num_feats, omit_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_aggr(avg_len=6, roll_nr=[6, 12], agr_fn=['min', 'max', 'mean', 'median']):\n",
    "    \n",
    "    df, time_feats, black_list_feats, forrecast_feats = beginFE()\n",
    "    \n",
    "    df['windSpeed_log'] = (np.log(df[ df['windSpeed']>0 ]['windSpeed']+5))\n",
    "    df['windGust_log']  = (np.log(df[ df['windGust']>0  ]['windGust']+2))\n",
    "    \n",
    "    obj_feats = df.select_dtypes(np.object).columns\n",
    "    for feat in obj_feats:\n",
    "        df[feat + '_cat'] = df[feat].factorize()[0]\n",
    "        \n",
    "    past_feats = df.select_dtypes(include=[np.number, bool]).columns.values\n",
    "    past_feats = [feat for feat in past_feats if feat not in black_list_feats]\n",
    "    past_feats = [feat for feat in past_feats if feat not in time_feats]\n",
    "    \n",
    "    roll_columns = [feat for feat in past_feats if not feat.endswith('_cat')]   \n",
    "    \n",
    "    for r_feat in roll_columns:\n",
    "        for fn in agr_fn:\n",
    "            for nr in roll_nr:    \n",
    "                suffix = '_roll{}{}'.format(nr, fn)\n",
    "                df[r_feat + suffix] = getattr(df[r_feat].rolling(nr), fn)()\n",
    "    roll_feats = [feat for feat in df.columns if '_roll' in feat]\n",
    "        \n",
    "    df['avg_mov'] = df['pm25'].rolling( window=avg_len, min_periods=1).mean()\n",
    "    df['avg_mov'] = df.apply(lambda x: np.nan if np.isnan(x['pm25']) else x['avg_mov'], axis=1)\n",
    "    df['avg_diff'] = df.apply(lambda x: x['pm25']-x['avg_mov'], axis=1)\n",
    "    \n",
    "#     df['avg_diff'][df['avg_diff'] > 30] = 30                                   # cap value\n",
    "#     df['avg_diff'][df['avg_diff'] < -30] = -30\n",
    "    \n",
    "    time_feats += forrecast_feats\n",
    "    \n",
    "    df, train, test, parts, num_feats, omit_feats = endFE(df, black_list_feats)\n",
    "\n",
    "    return df, train, test, parts, num_feats, omit_feats, time_feats, black_list_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# możliwość podania dowolnej ilosci punktów do predykcji\n",
    "# bez uwzglednienia przesunięcia cech\n",
    "\n",
    "def run_model_nr(nr, model_selected, model_params, parts_to_go, feats_selected, y_log):\n",
    "    \n",
    "    train_df, y_train_all = pd.DataFrame(columns=feats_selected), np.array([])\n",
    "    last_days_df, y_last_days, y_last_pred, y_pred_all = train_df.copy(), np.array([]), np.array([]), np.array([])\n",
    "    models, global_scores, last_day_scores = [], np.array([]), np.array([])\n",
    "\n",
    "    for i in np.arange(nr):\n",
    "        models.append(model_selected(**model_params))          # odzielne modele dla 24h\n",
    "    \n",
    "    for train in tqdm(parts_to_go):                               # kolejne bloki danych\n",
    "  \n",
    "        X = train[feats_selected].values\n",
    "        y = (train['pm25'].values).astype(np.float64)\n",
    "        if y_log:\n",
    "            y = (train['pm25_log'].values).astype(np.float64)\n",
    "   \n",
    "        X_last  = X[-25:-24]                                    # ostatni wiersz z bloku danych\n",
    "        X_train = X[0:-25]                                      # pomija zbiór testowy i ostatni wiersz\n",
    "        \n",
    "        for i in np.arange(nr):                                 # każdy model szkolony oddzielnie\n",
    "            y = pd.Series(y).shift(-1).values                   # przesuwa pm25 o 1h w przeszłość\n",
    "            y_train = y[0:-25]                       \n",
    "            models[i].fit(X_train, y_train)                        \n",
    "            y_last = (models[i].predict(X_last)).astype(np.float64)\n",
    "            y[-25] = y_last[0]                                  # prognoza na 1h\n",
    "        \n",
    "        y_pred = y[-nr-24:-24]                                  # prognoza na 24h\n",
    "        if y_log:\n",
    "            y_pred = np.exp(y_pred)-1\n",
    "         \n",
    "        #last day CV\n",
    "        \n",
    "        X_last_day = X[-nr-25:-nr-24]                           # godzina poprzedzająca ostatni dzień z danymi\n",
    "        y_last_day = train.pm25[-nr-25:-25].values\n",
    "        y_last_p = np.array([])\n",
    "        for i in np.arange(nr):                     \n",
    "            y_hour = (models[i].predict(X_last_day)).astype(np.float64)\n",
    "            y_last_p = np.concatenate((y_last_p, y_hour))\n",
    "        if y_log:\n",
    "            y_last_p = np.exp(y_last_p)-1\n",
    "        last_day_scores = np.append( last_day_scores, [rmse(y_last_day, y_last_p)] )\n",
    "            \n",
    "        train_df     = train_df + train[feats_selected][0:-25]\n",
    "        last_days_df = last_days_df + train[feats_selected][-nr-25:-25]\n",
    "        y_train_all  = np.concatenate((y_train_all, train.pm25[0:-25].values))\n",
    "        y_last_days  = np.concatenate((y_last_days, y_last_day))\n",
    "        y_last_pred  = np.concatenate((y_last_pred, y_last_p))\n",
    "        y_pred_all   = np.concatenate((y_pred_all, y_pred))\n",
    "        \n",
    "        # CV\n",
    "        \n",
    "        side = 2  # pozwala uniknąć cyklicznych podobieństw parametru - dla 2 sprawdza 5 sąsiednich wartosci\n",
    "        part_scores = np.array([])\n",
    "        for i in np.arange(nr):                         # waliduje każdy model osobno\n",
    "            scores = np.array([])\n",
    "            for shift in np.arange(-i-side, -i+side):   # przesunięcia wykresu - kiedy bład będzie najmniejszy?\n",
    "                X_cv = train[feats_selected][0:-25].values\n",
    "                y_cv = train.pm25[0:-25].values\n",
    "                if y_log:\n",
    "                    y_cv = train.pm25_log[0:-25].values\n",
    "                y_cv = pd.Series(y_cv).shift(shift).values    # przesuwa y w przeszłośc (wartości ujemne)\n",
    "                y_pred_cv = (models[i].predict(X_cv)).astype(np.float64)\n",
    "                if y_log: \n",
    "                    y_cv = np.exp(y_cv)-1\n",
    "                    y_pred_cv = np.exp(y_pred_cv)-1\n",
    "                scores = np.append( scores, [rmse(y_cv[side:-side-nr], y_pred_cv[side:-side-nr])] )\n",
    "            part_scores = np.append( part_scores, [scores[scores.argmin()]] )\n",
    "#         print(part_scores.mean(), part_scores.std())\n",
    "\n",
    "        global_scores = np.append( global_scores, part_scores )\n",
    "    r2_total = r2_score(y_last_days, y_last_pred)\n",
    "    rmse_total = rmse(y_last_days, y_last_pred)\n",
    "    print('shift_score: {:.3f}, last_24_score: {:.3f}, rmse: {:.3f}, r2: {:.3f}\\n'.format(global_scores.mean(),\n",
    "                                                                                        last_day_scores.mean(),\n",
    "                                                                                        rmse_total, r2_total))      \n",
    "    return (global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pomija ostatni okres w zbiorze testowym i używa go do walidacji\n",
    "# bez uwzglednienia przesunięcia cech\n",
    "\n",
    "def run_model_day(nr, model_selected, model_params, parts_to_go, feats_selected, y_log):\n",
    "    \n",
    "    train_df, y_train_all = pd.DataFrame(columns=feats_selected), np.array([])\n",
    "    last_days_df, y_last_days, y_last_pred, y_pred_all = train_df.copy(), np.array([]), np.array([]), np.array([])\n",
    "    models, global_scores, last_day_scores = [], np.array([]), np.array([])\n",
    "\n",
    "    for i in np.arange(nr):\n",
    "        models.append(model_selected(**model_params))          # odzielne modele dla 24h\n",
    "    \n",
    "    for train in tqdm(parts_to_go):                               # kolejne bloki danych\n",
    "  \n",
    "        X = train[feats_selected].values\n",
    "        y = (train['pm25'].values).astype(np.float64)\n",
    "        if y_log:\n",
    "            y = (train['pm25_log'].values).astype(np.float64)\n",
    "   \n",
    "        X_last  = X[-25:-24]                                    # ostatni wiersz z bloku danych\n",
    "        X_train = X[0:-nr-25]                                   # pomija zbiór testowy, ostatni wiersz i ostatni dzień (CV)\n",
    "        \n",
    "        for i in np.arange(nr):                                 # każdy model szkolony oddzielnie\n",
    "            y = pd.Series(y).shift(-1).values                   # przesuwa pm25 o 1h w przeszłość\n",
    "            y_train = y[0:-nr-25]                       \n",
    "            models[i].fit(X_train, y_train)                        \n",
    "            y_last = (models[i].predict(X_last)).astype(np.float64)\n",
    "            y[-25] = y_last[0]                                  # prognoza na 1h\n",
    "        \n",
    "        y_pred = y[-nr-24:-24]                                     # prognoza na 24 h (nr)\n",
    "        if y_log:\n",
    "            y_pred = np.exp(y_pred)-1\n",
    "        \n",
    "        #last day CV\n",
    "        \n",
    "        X_last_day = X[-nr-25:-nr-24]                                 # godzina poprzedzająca ostatni dzień z danymi\n",
    "        y_last_day = train.pm25[-nr-25:-25].values\n",
    "        y_last_p = np.array([])\n",
    "        for i in np.arange(nr):                     \n",
    "            y_hour = (models[i].predict(X_last_day)).astype(np.float64)\n",
    "            y_last_p = np.concatenate((y_last_p, y_hour))\n",
    "        if y_log:\n",
    "            y_last_p = np.exp(y_last_p)-1\n",
    "        last_day_scores = np.append( last_day_scores, [rmse(y_last_day, y_last_p)] )\n",
    "            \n",
    "        train_df     = train_df + train[feats_selected][0:-nr-25]\n",
    "        last_days_df = last_days_df + train[feats_selected][-nr-25:-25]\n",
    "        y_train_all  = np.concatenate((y_train_all, train.pm25[0:-nr-25].values))\n",
    "        y_last_days  = np.concatenate((y_last_days, y_last_day))\n",
    "        y_last_pred  = np.concatenate((y_last_pred, y_last_p))\n",
    "        y_pred_all   = np.concatenate((y_pred_all, y_pred))\n",
    "        \n",
    "        # CV\n",
    "        \n",
    "        side = 2  # pozwala uniknąć cyklicznych podobieństw parametru - dla 2 sprawdza 5 sąsiednich wartosci\n",
    "        part_scores = np.array([])\n",
    "        for i in np.arange(nr):                         # waliduje każdy model osobno\n",
    "            scores = np.array([])\n",
    "            for shift in np.arange(-i-side, -i+side):         # sprawdza przesunięcia wykresu - kiedy bład będzie najmniejszy?\n",
    "                X_cv = train[feats_selected][0:-25].values\n",
    "                y_cv = train.pm25[0:-25].values\n",
    "                if y_log:\n",
    "                    y_cv = train.pm25_log[0:-25].values\n",
    "                y_cv = pd.Series(y_cv).shift(shift).values    # przesuwa y w przeszłośc (wartości ujemne)\n",
    "                y_pred_cv = (models[i].predict(X_cv)).astype(np.float64)\n",
    "                if y_log: \n",
    "                    y_cv = np.exp(y_cv)-1\n",
    "                    y_pred_cv = np.exp(y_pred_cv)-1\n",
    "                scores = np.append( scores, [rmse(y_cv[side:-side-nr], y_pred_cv[side:-side-nr])] )\n",
    "            part_scores = np.append( part_scores, [scores[scores.argmin()]] )\n",
    "#         print(part_scores.mean(), part_scores.std())\n",
    "\n",
    "        global_scores = np.append( global_scores, part_scores )\n",
    "    r2_total = r2_score(y_last_days, y_last_pred)\n",
    "    rmse_total = rmse(y_last_days, y_last_pred)\n",
    "    print('shift_score: {:.3f}, last_24_score: {:.3f}, rmse: {:.3f}, r2: {:.3f}\\n'.format(global_scores.mean(),\n",
    "                                                                                        last_day_scores.mean(),\n",
    "                                                                                        rmse_total, r2_total))      \n",
    "    return (global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 61) (38952, 61) (1200, 61) 50 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d7f0d27b664d22b966000981abfa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shift_score: 0.382, last_24_score: 3.490, rmse: 4.007, r2: 0.954\n",
      "\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ostani dzień w zbiorze treningowym - model finałowy\n",
    "\n",
    "name = 'avg_18.p'\n",
    "log_y = False\n",
    "df, train, test, parts, num_feats, omit_feats, time_feats, black_list_feats = \\\n",
    "    feature_engineering_aggr(avg_len=6, roll_nr=[24], agr_fn=['median'])\n",
    "feats = num_feats\n",
    "print(df.shape, train.shape, test.shape, len(parts), len(feats))\n",
    "with_params = {\n",
    "    'model_selected': xgb.XGBRegressor,\n",
    "    'model_params'  : {'learning_rate': 0.2476843816313341, \n",
    "                         'max_depth': 5, \n",
    "                         'n_estimators': 100, \n",
    "                         'n_jobs': 8, \n",
    "                         'objective': 'reg:squarederror', \n",
    "                         'random_state': 70, \n",
    "                         'subsample': 0.8561623057645249, \n",
    "                        },\n",
    "    'parts_to_go'     : parts, \n",
    "    'feats_selected'  : feats,\n",
    "    'y_log'           : log_y,\n",
    "    'nr'              : 24\n",
    "}\n",
    "global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected = run_model_nr(**with_params)\n",
    "\n",
    "result = global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected\n",
    "with open(name, 'wb') as f:\n",
    "    pickle.dump(result, f)\n",
    "test['pm25'] = y_pred_all\n",
    "test[ ['id', 'pm25'] ].to_csv('late_nr_{}.csv'.format(name[:-2]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                            | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9747af52dca24f92a61622ac80b19398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_score: 0.076, last_24_score: 4.211, rmse: 5.691, r2: 0.907                                                       \n",
      "\n",
      "{'agr_fn': ('median',), 'avg_len': 24, 'learning_rate': 0.2684062129677209, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1, 'objective': 'reg:squarederror', 'random_state': 582, 'roll_nr': (24,), 'subsample': 0.8614156053325035, 'y_log': True}\n",
      "_                                                                                                                      \n",
      "\n",
      "100%|██████████████████████████████████████████████████| 1/1 [08:20<00:00, 500.26s/trial, best loss: 4.210761487900741]\n",
      "The best params:  {'x_agr_fn': 1, 'x_avg_len': 3, 'x_learning_rate': 0.2684062129677209, 'x_max_depth': 2, 'x_n_estimators': 1, 'x_random_state': 581, 'x_roll_nr': 3, 'x_subsample': 0.8614156053325035, 'x_y_log': 0}\n"
     ]
    }
   ],
   "source": [
    "# poszukiwanie optymalnych parametrów dla modeli agregacyjnych, walidacja last day\n",
    "# bez uwzglednienia przesunięcia cech\n",
    "\n",
    "def space_to_param(space):\n",
    "    int_param = ['max_depth', 'random_state', 'min_child_weight', 'n_estimators', 'n_jobs']\n",
    "    \n",
    "    params  = {}\n",
    "    for x in space:\n",
    "        if x == 'y_log':            y_log  = space[x]\n",
    "        if x == 'avg_len':        avg_len  = int(space[x])\n",
    "        if x == 'roll_nr':        roll_nr  = space[x]\n",
    "        if x == 'agr_fn':          agr_fn  = space[x]    \n",
    "        if x in int_param:       params[x] = int(space[x])   \n",
    "        else:                    params[x] = space[x]            \n",
    "    return y_log, params, roll_nr, agr_fn, avg_len\n",
    "\n",
    "def param_opt(space):\n",
    "\n",
    "    y_log, params, roll_nr, agr_fn, avg_len = space_to_param(space)\n",
    "    \n",
    "    df, train, test, parts, num_feats, omit_feats, time_feats, black_list_feats = \\\n",
    "        feature_engineering_aggr(avg_len=avg_len, roll_nr=roll_nr, agr_fn=agr_fn)\n",
    "    feats = num_feats\n",
    "    \n",
    "    with_params = {\n",
    "        'model_params'   : params,\n",
    "        'parts_to_go'    : parts,\n",
    "        'y_log'          : y_log,\n",
    "        'feats_selected' : feats,\n",
    "        'nr'             : 24,\n",
    "        'model_selected' : xgb.XGBRegressor,\n",
    "    }\n",
    "      \n",
    "    global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected =  run_model_day(**with_params)\n",
    "    print(params, '_\\n')\n",
    "\n",
    "    return{'loss': last_day_scores.mean(), 'status': STATUS_OK }\n",
    "\n",
    "space ={\n",
    "    'subsample'      : hp.uniform('x_subsample', 0.7, 1.),\n",
    "    'learning_rate'  : hp.uniform('x_learning_rate', 0.05, 0.3),\n",
    "    'random_state'   : hp.choice('x_random_state', range(1, 1000, 1)),\n",
    "    'max_depth'      : hp.choice('x_max_depth', range(5, 8, 1)),\n",
    "    'roll_nr'        : hp.choice('x_roll_nr', [[6], [12], [18], [24], [6, 12], [12, 18], [18, 24], \\\n",
    "                                               [6, 24], [6, 18], [12, 24]]),\n",
    "    'agr_fn'         : hp.choice('x_agr_fn', [['mean'], ['median'], ['mean', 'median']]),\n",
    "    'n_estimators'   : hp.choice('x_n_estimators', range(50, 300, 50)),\n",
    "    'objective'      : 'reg:squarederror',\n",
    "    'n_jobs'         : -1,\n",
    "    'y_log'          : hp.choice('x_y_log', [True, False]),\n",
    "    'avg_len'        : hp.choice('x_avg_len', [6, 12, 18, 24]),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=param_opt,\n",
    "            space=space,\n",
    "            algo=partial(tpe.suggest, n_startup_jobs=1),\n",
    "            max_evals=1,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"The best params: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przesuwa dane które znamy w przyszłości (zmienne zależne od czasu, prognozy, ewentualnie wyliczone średnie np. dla dni tygodnia)\n",
    "# muszą być określone w zbiorze testowym\n",
    "\n",
    "def shift_X(X, feats, nr=-1):\n",
    "    for feat in feats:\n",
    "        X[feat] = X[feat].shift(nr)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ostatni dzień w zbiorze treningowym\n",
    "# przesunięcie danych znanych w przyszłości\n",
    "\n",
    "def run_model_nr_X_shift(nr, model_selected, model_params, parts_to_go, feats_selected, time_feats, y_log):\n",
    "    \n",
    "    train_df, y_train_all = pd.DataFrame(columns=feats_selected), np.array([])\n",
    "    last_days_df, y_last_days, y_last_pred, y_pred_all = train_df.copy(), np.array([]), np.array([]), np.array([])\n",
    "    models, global_scores, last_day_scores = [], np.array([]), np.array([])\n",
    "\n",
    "    for i in np.arange(nr):\n",
    "        models.append(model_selected(**model_params))          # odzielne modele dla 24h\n",
    "    \n",
    "    for train in tqdm(parts_to_go):                               # kolejne bloki danych\n",
    "  \n",
    "        X = train[feats_selected]\n",
    "        y = (train['pm25'].values).astype(np.float64)\n",
    "        if y_log:\n",
    "            y = (train['pm25_log'].values).astype(np.float64)\n",
    "        \n",
    "        for i in np.arange(nr):                             # każdy model szkolony oddzielnie\n",
    "            X = shift_X(X, time_feats, -1)                  # przesuwa kolumny znane w przyszłości - time_feats\n",
    "            X_last  = X[-25:-24].values                            # ostatni wiersz z bloku danych - do predykcji\n",
    "            X_train = X[0:-25].values                              # pomija zbiór testowy i ostatni wiersz\n",
    "            y = pd.Series(y).shift(-1).values               # przesuwa pm25 o 1h w przeszłość\n",
    "            y_train = y[0:-25]                       \n",
    "            models[i].fit(X_train, y_train)                        \n",
    "            y_last = (models[i].predict(X_last)).astype(np.float64)\n",
    "            y[-25] = y_last[0]                                  # prognoza na 1h\n",
    "        \n",
    "        y_pred = y[-nr-24:-24]                                  # prognoza na 24h\n",
    "        if y_log:\n",
    "            y_pred = np.exp(y_pred)-1\n",
    "         \n",
    "        #last day CV\n",
    "        \n",
    "        X = train[feats_selected]\n",
    "        y_last_day = train.pm25[-nr-25:-25].values\n",
    "        y_last_p = np.array([])\n",
    "        for i in np.arange(nr):\n",
    "            X = shift_X(X, time_feats, -1)\n",
    "            X_last_day = X[-nr-25:-nr-24].values                           # godzina poprzedzająca ostatni dzień z danymi\n",
    "            y_hour = (models[i].predict(X_last_day)).astype(np.float64)\n",
    "            y_last_p = np.concatenate((y_last_p, y_hour))\n",
    "        if y_log:\n",
    "            y_last_p = np.exp(y_last_p)-1\n",
    "        last_day_scores = np.append( last_day_scores, [rmse(y_last_day, y_last_p)] )\n",
    "            \n",
    "        train_df     = train_df + train[feats_selected][0:-25]\n",
    "        last_days_df = last_days_df + train[feats_selected][-nr-25:-25]\n",
    "        y_train_all  = np.concatenate((y_train_all, train.pm25[0:-25].values))\n",
    "        y_last_days  = np.concatenate((y_last_days, y_last_day))\n",
    "        y_last_pred  = np.concatenate((y_last_pred, y_last_p))\n",
    "        y_pred_all   = np.concatenate((y_pred_all, y_pred))\n",
    "        \n",
    "        # CV\n",
    "        \n",
    "        side = 2  # pozwala uniknąć cyklicznych podobieństw parametru - dla 2 sprawdza 5 sąsiednich wartosci\n",
    "        part_scores = np.array([])\n",
    "        for i in np.arange(nr):                         # waliduje każdy model osobno\n",
    "            scores = np.array([])\n",
    "            for shift in np.arange(-i-side, -i+side):   # przesunięcia wykresu - kiedy bład będzie najmniejszy?\n",
    "                X_cv = train[feats_selected][0:-25]\n",
    "                y_cv = train.pm25[0:-25].values\n",
    "                if y_log:\n",
    "                    y_cv = train.pm25_log[0:-25].values\n",
    "                y_cv = pd.Series(y_cv).shift(shift).values    # przesuwa y w przeszłośc (wartości ujemne)\n",
    "                X_cv = shift_X(X_cv, time_feats, shift)\n",
    "                y_pred_cv = (models[i].predict(X_cv.values)).astype(np.float64)\n",
    "                if y_log: \n",
    "                    y_cv = np.exp(y_cv)-1\n",
    "                    y_pred_cv = np.exp(y_pred_cv)-1\n",
    "                scores = np.append( scores, [rmse(y_cv[side:-side-nr], y_pred_cv[side:-side-nr])] )\n",
    "            part_scores = np.append( part_scores, [scores[scores.argmin()]] )\n",
    "#         print(part_scores.mean(), part_scores.std())\n",
    "\n",
    "        global_scores = np.append( global_scores, part_scores )\n",
    "    r2_total = r2_score(y_last_days, y_last_pred)\n",
    "    rmse_total = rmse(y_last_days, y_last_pred)\n",
    "    print('shift_score: {:.3f}, last_24_score: {:.3f}, rmse: {:.3f}, r2: {:.3f}\\n'.format(global_scores.mean(),\n",
    "                                                                                        last_day_scores.mean(),\n",
    "                                                                                        rmse_total, r2_total))      \n",
    "    return (global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uwzgledniając przesunięcie kolumn zależnych od czasu poprawa wyniku do 12.96040 z 13.33315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 61) (38952, 61) (1200, 61) 50 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc646875b814e55aee20dba96a87523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shift_score: 0.381, last_24_score: 3.500, rmse: 4.009, r2: 0.954\n",
      "\n",
      "Wall time: 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'X_shift_avg_18.p'\n",
    "log_y = False\n",
    "df, train, test, parts, num_feats, omit_feats, time_feats, black_list_feats = \\\n",
    "    feature_engineering_aggr(avg_len=6, roll_nr=[24], agr_fn=['median'])\n",
    "feats = num_feats\n",
    "print(df.shape, train.shape, test.shape, len(parts), len(feats))\n",
    "with_params = {\n",
    "    'model_selected': xgb.XGBRegressor,\n",
    "    'model_params'  : {'learning_rate': 0.2476843816313341, \n",
    "                         'max_depth': 5, \n",
    "                         'n_estimators': 100, \n",
    "                         'n_jobs': -1, \n",
    "                         'objective': 'reg:squarederror', \n",
    "                         'random_state': 70, \n",
    "                         'subsample': 0.8561623057645249, \n",
    "                        },\n",
    "    'parts_to_go'     : parts, \n",
    "    'feats_selected'  : feats,\n",
    "    'time_feats'      : time_feats,\n",
    "    'y_log'           : log_y,\n",
    "    'nr'              : 24\n",
    "}\n",
    "global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected = run_model_nr_X_shift(**with_params)\n",
    "\n",
    "result = global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected\n",
    "with open(name, 'wb') as f:\n",
    "    pickle.dump(result, f)\n",
    "test['pm25'] = y_pred_all\n",
    "test[ ['id', 'pm25'] ].to_csv('late_nr_{}.csv'.format(name[:-2]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ostatni dzień pominięty w zbiorze treningowym - użyty do walidacji, stosujemy do hyperopt\n",
    "\n",
    "def run_model_day_X_shift(nr, model_selected, model_params, parts_to_go, feats_selected, time_feats, y_log):\n",
    "    \n",
    "    train_df, y_train_all = pd.DataFrame(columns=feats_selected), np.array([])\n",
    "    last_days_df, y_last_days, y_last_pred, y_pred_all = train_df.copy(), np.array([]), np.array([]), np.array([])\n",
    "    models, global_scores, last_day_scores = [], np.array([]), np.array([])\n",
    "\n",
    "    for i in np.arange(nr):\n",
    "        models.append(model_selected(**model_params))          # odzielne modele dla 24h\n",
    "    \n",
    "    for train in tqdm(parts_to_go):                               # kolejne bloki danych\n",
    "  \n",
    "        X = train[feats_selected]\n",
    "        y = (train['pm25'].values).astype(np.float64)\n",
    "        if y_log:\n",
    "            y = (train['pm25_log'].values).astype(np.float64)\n",
    "        \n",
    "        for i in np.arange(nr):                             # każdy model szkolony oddzielnie\n",
    "            X = shift_X(X, time_feats, -1)                  # przesuwa kolumny znane w przyszłości - time_feats\n",
    "            X_last  = X[-25:-24].values                     # ostatni wiersz z bloku danych - do predykcji\n",
    "            X_train = X[0:-nr-25].values                    # pomija zbiór testowy, ostatni dzień i ostatni wiersz\n",
    "            y = pd.Series(y).shift(-1).values               # przesuwa pm25 o 1h w przeszłość\n",
    "            y_train = y[0:-nr-25]                     \n",
    "            models[i].fit(X_train, y_train)                        \n",
    "            y_last = (models[i].predict(X_last)).astype(np.float64)\n",
    "            y[-25] = y_last[0]                                  # prognoza na 1h\n",
    "        \n",
    "        y_pred = y[-nr-24:-24]                                  # prognoza na 24h\n",
    "        if y_log:\n",
    "            y_pred = np.exp(y_pred)-1\n",
    "         \n",
    "        #last day CV\n",
    "        \n",
    "        X = train[feats_selected]\n",
    "        y_last_day = train.pm25[-nr-25:-25].values\n",
    "        y_last_p = np.array([])\n",
    "        for i in np.arange(nr):\n",
    "            X = shift_X(X, time_feats, -1)\n",
    "            X_last_day = X[-nr-25:-nr-24].values                           # godzina poprzedzająca ostatni dzień z danymi\n",
    "            y_hour = (models[i].predict(X_last_day)).astype(np.float64)\n",
    "            y_last_p = np.concatenate((y_last_p, y_hour))\n",
    "        if y_log:\n",
    "            y_last_p = np.exp(y_last_p)-1\n",
    "        last_day_scores = np.append( last_day_scores, [rmse(y_last_day, y_last_p)] )\n",
    "            \n",
    "        train_df     = train_df + train[feats_selected][0:-nr-25]\n",
    "        last_days_df = last_days_df + train[feats_selected][-nr-25:-25]\n",
    "        y_train_all  = np.concatenate((y_train_all, train.pm25[0:-nr-25].values))\n",
    "        y_last_days  = np.concatenate((y_last_days, y_last_day))\n",
    "        y_last_pred  = np.concatenate((y_last_pred, y_last_p))\n",
    "        y_pred_all   = np.concatenate((y_pred_all, y_pred))\n",
    "        \n",
    "        # CV\n",
    "        \n",
    "        side = 2  # pozwala uniknąć cyklicznych podobieństw parametru - dla 2 sprawdza 5 sąsiednich wartosci\n",
    "        part_scores = np.array([])\n",
    "        for i in np.arange(nr):                         # waliduje każdy model osobno\n",
    "            scores = np.array([])\n",
    "            for shift in np.arange(-i-side, -i+side):   # przesunięcia wykresu - kiedy bład będzie najmniejszy?\n",
    "                X_cv = train[feats_selected][0:-nr-25]\n",
    "                y_cv = train.pm25[0:-nr-25].values\n",
    "                if y_log:\n",
    "                    y_cv = train.pm25_log[0:-nr-25].values\n",
    "                y_cv = pd.Series(y_cv).shift(shift).values    # przesuwa y w przeszłośc (wartości ujemne)\n",
    "                X_cv = shift_X(X_cv, time_feats, shift)\n",
    "                y_pred_cv = (models[i].predict(X_cv.values)).astype(np.float64)\n",
    "                if y_log: \n",
    "                    y_cv = np.exp(y_cv)-1\n",
    "                    y_pred_cv = np.exp(y_pred_cv)-1\n",
    "                scores = np.append( scores, [rmse(y_cv[side:-side-nr], y_pred_cv[side:-side-nr])] )\n",
    "            part_scores = np.append( part_scores, [scores[scores.argmin()]] )\n",
    "#         print(part_scores.mean(), part_scores.std())\n",
    "\n",
    "        global_scores = np.append( global_scores, part_scores )\n",
    "    r2_total = r2_score(y_last_days, y_last_pred)\n",
    "    rmse_total = rmse(y_last_days, y_last_pred)\n",
    "    print('shift_score: {:.3f}, last_24_score: {:.3f}, rmse: {:.3f}, r2: {:.3f}\\n'.format(global_scores.mean(),\n",
    "                                                                                        last_day_scores.mean(),\n",
    "                                                                                        rmse_total, r2_total))      \n",
    "    return (global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 79) (38952, 79) (1200, 79) 50 68                                                                               \n",
      "  0%|                                                                            | 0/1 [00:04<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15131ad1398f426d945aeddf68b2a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_score: 0.785, last_24_score: 3.815, rmse: 4.876, r2: 0.932                                                       \n",
      "\n",
      "{'agr_fn': ('median',), 'avg_len': 6, 'learning_rate': 0.1279118891350392, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': 8, 'objective': 'reg:squarederror', 'random_state': 123, 'roll_nr': (6, 12), 'subsample': 0.9729745085631428, 'y_log': False}\n",
      "100%|██████████████████████████████████████████████████| 1/1 [06:32<00:00, 392.16s/trial, best loss: 4.876393392308629]\n",
      "The best params:  {'x_agr_fn': 0, 'x_avg_len': 0, 'x_learning_rate': 0.1279118891350392, 'x_max_depth': 1, 'x_n_estimators': 1, 'x_random_state': 0, 'x_roll_nr': 4, 'x_subsample': 0.9729745085631428, 'x_y_log': 1}\n"
     ]
    }
   ],
   "source": [
    "# poszukiwanie optymalnych parametrów dla modeli agregacyjnych, walidacja last day\n",
    "# uwzglednienia przesunięcie cech znanych w przyszłości\n",
    "\n",
    "def space_to_param(space):\n",
    "    int_param = ['max_depth', 'random_state', 'min_child_weight', 'n_estimators', 'n_jobs']\n",
    "    \n",
    "    params  = {}\n",
    "    for x in space:\n",
    "        if x == 'y_log':            y_log  = space[x]\n",
    "        if x == 'avg_len':        avg_len  = int(space[x])\n",
    "        if x == 'roll_nr':        roll_nr  = space[x]\n",
    "        if x == 'agr_fn':          agr_fn  = space[x]    \n",
    "        if x in int_param:       params[x] = int(space[x])   \n",
    "        else:                    params[x] = space[x]            \n",
    "    return y_log, params, roll_nr, agr_fn, avg_len\n",
    "\n",
    "def param_opt(space):\n",
    "\n",
    "    y_log, params, roll_nr, agr_fn, avg_len = space_to_param(space)\n",
    "    \n",
    "    df, train, test, parts, num_feats, omit_feats, time_feats, black_list_feats = \\\n",
    "        feature_engineering_aggr(avg_len=avg_len, roll_nr=roll_nr, agr_fn=agr_fn)\n",
    "    feats = num_feats\n",
    "    print(\"{} {} {} {} {}\".format(df.shape, train.shape, test.shape, len(parts), len(feats)))\n",
    "    with_params = {\n",
    "        'model_params'   : params,\n",
    "        'parts_to_go'    : parts,\n",
    "        'y_log'          : y_log,\n",
    "        'feats_selected' : feats,\n",
    "        'time_feats'     : time_feats,\n",
    "        'nr'             : 24,\n",
    "        'model_selected' : xgb.XGBRegressor,\n",
    "    }\n",
    "      \n",
    "    global_scores, last_day_scores, rmse_total, r2_total, models, y_pred_all, train_df, last_days_df, \\\n",
    "            y_train_all, y_last_days, y_last_pred, feats_selected = run_model_day_X_shift(**with_params)\n",
    "    print(\"{}\".format(params))\n",
    "    \n",
    "    return{'loss': rmse_total, 'status': STATUS_OK }\n",
    "\n",
    "space ={\n",
    "    'subsample'      : hp.uniform('x_subsample', 0.7, 1.),\n",
    "    'learning_rate'  : hp.uniform('x_learning_rate', 0.05, 0.3),\n",
    "    'random_state'   : hp.choice('x_random_state', [123]),\n",
    "    'max_depth'      : hp.choice('x_max_depth', [4, 5]),\n",
    "    'roll_nr'        : hp.choice('x_roll_nr', [[6], [12], [18], [24], [6, 12], [12, 18], [18, 24], \\\n",
    "                                               [6, 24], [6, 18], [12, 24]]),\n",
    "    'agr_fn'         : hp.choice('x_agr_fn', [['median']]),\n",
    "    'n_estimators'   : hp.choice('x_n_estimators', [50, 100]),\n",
    "    'objective'      : 'reg:squarederror',\n",
    "    'n_jobs'         : 8,\n",
    "    'y_log'          : hp.choice('x_y_log', [True, False]),\n",
    "    'avg_len'        : hp.choice('x_avg_len', [6, 12, 18, 24]),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=param_opt,\n",
    "            space=space,\n",
    "            algo=partial(tpe.suggest, n_startup_jobs=1),\n",
    "            max_evals=1,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"The best params: \", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
